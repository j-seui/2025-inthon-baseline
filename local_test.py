import sys

import os

from pathlib import Path

import importlib.util

import time

import torch

import tempfile

import shutil


def get_all_devices_from_model(model) -> set:
    """
    ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ì™€ ë²„í¼ë¥¼ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ ì‹¤ì œ deviceë¥¼ í™•ì¸
    
    ëª¨ë¸ êµ¬ì¡°ê°€ ììœ ë¡­ê²Œ ë°”ë€” ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ëª¨ë“  ì†ì„±ì„ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.
    
    Returns:
        ë°œê²¬ëœ ëª¨ë“  deviceì˜ ì§‘í•©
    """
    devices = set()
    visited = set()  # ìˆœí™˜ ì°¸ì¡° ë°©ì§€
    
    def traverse(obj, depth=0):
        """ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  í…ì„œë¥¼ íƒìƒ‰"""
        if depth > 30:  # ê¹Šì´ ì œí•œ
            return
        
        # ìˆœí™˜ ì°¸ì¡° ë°©ì§€ (id ê¸°ë°˜)
        try:
            obj_id = id(obj)
            if obj_id in visited:
                return
            visited.add(obj_id)
        except TypeError:
            # id()ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê°ì²´ (ì˜ˆ: None, ìˆ«ì ë“±)
            pass
        
        # PyTorch ëª¨ë“ˆì¸ ê²½ìš°
        if isinstance(obj, torch.nn.Module):
            try:
                # ëª¨ë“  íŒŒë¼ë¯¸í„° í™•ì¸
                for param in obj.parameters(recurse=False):  # í˜„ì¬ ëª¨ë“ˆë§Œ
                    if param.is_cuda:
                        devices.add(f"cuda:{param.device.index}" if param.device.index is not None else "cuda")
                    else:
                        devices.add("cpu")
                
                # ëª¨ë“  ë²„í¼ í™•ì¸
                for buffer in obj.buffers(recurse=False):  # í˜„ì¬ ëª¨ë“ˆë§Œ
                    if buffer.is_cuda:
                        devices.add(f"cuda:{buffer.device.index}" if buffer.device.index is not None else "cuda")
                    else:
                        devices.add("cpu")
                
                # ëª¨ë“  í•˜ìœ„ ëª¨ë“ˆ ì¬ê·€ íƒìƒ‰
                for name, child in obj.named_children():
                    traverse(child, depth + 1)
            except Exception:
                pass  # ëª¨ë“ˆ íƒìƒ‰ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        # í…ì„œì¸ ê²½ìš°
        elif isinstance(obj, torch.Tensor):
            try:
                if obj.is_cuda:
                    devices.add(f"cuda:{obj.device.index}" if obj.device.index is not None else "cuda")
                else:
                    devices.add("cpu")
            except Exception:
                pass
        
        # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
        elif isinstance(obj, dict):
            for value in obj.values():
                traverse(value, depth + 1)
        
        # ë¦¬ìŠ¤íŠ¸ë‚˜ íŠœí”Œì¸ ê²½ìš°
        elif isinstance(obj, (list, tuple)):
            for item in obj:
                traverse(item, depth + 1)
        
        # ì¼ë°˜ ê°ì²´ì¸ ê²½ìš° - ì£¼ìš” ì†ì„±ë“¤ í™•ì¸ (ê¹Šì´ ì œí•œ)
        elif depth < 10 and hasattr(obj, '__dict__'):
            try:
                # __dict__ì˜ ê°’ë“¤ë§Œ í™•ì¸ (ë©”ì„œë“œ í˜¸ì¶œ ìµœì†Œí™”)
                if hasattr(obj, '__dict__'):
                    for value in obj.__dict__.values():
                        traverse(value, depth + 1)
            except Exception:
                pass
    
    # ëª¨ë¸ ìì²´ë¶€í„° ì‹œì‘
    traverse(model)
    
    # model.model ê°™ì€ ì¤‘ì²© êµ¬ì¡°ë„ ëª…ì‹œì ìœ¼ë¡œ í™•ì¸
    if hasattr(model, 'model'):
        traverse(model.model)
    
    return devices


def run_local_test(submission_dir_path: str):
    submission_path = Path(submission_dir_path).resolve()
    model_py_path = submission_path / "model.py"

    if not model_py_path.exists():
        print(f"ì˜¤ë¥˜: {submission_path}ì—ì„œ model.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    original_cwd = os.getcwd()
    os.chdir(submission_path)

    try:
        spec = importlib.util.spec_from_file_location("submission_main", model_py_path)
        module = importlib.util.module_from_spec(spec)
        assert spec is not None and spec.loader is not None
        spec.loader.exec_module(module)
        # Model í´ë˜ìŠ¤ ì¡´ì¬ ì—¬ë¶€

        if not hasattr(module, "Model"):
            print("âŒ model.py ì•ˆì— 'Model' í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        from do_not_edit.model_template import BaseModel
        ModelClass = getattr(module, "Model")
        if not issubclass(ModelClass, BaseModel):
            print("âŒ Model í´ë˜ìŠ¤ê°€ BaseModelì„ ìƒì†í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return

        # ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸

        try:
            model = ModelClass()

        except TypeError as e:
            print(f"âŒ Model() ì´ˆê¸°í™” ì‹¤íŒ¨ (ì¸ì ê´€ë ¨ ë¬¸ì œ ê°€ëŠ¥): {e}")
            return

        print("âœ… Model ì´ˆê¸°í™” ì™„ë£Œ.")
        
        # ìƒëŒ€ ê²½ë¡œ ê²€ì¦ (ì‹¤ì œ ë””ë ‰í† ë¦¬ ë³€ê²½ í…ŒìŠ¤íŠ¸)
        print("\n[ìƒëŒ€ ê²½ë¡œ ê²€ì¦]")
        print("   ë‹¤ë¥¸ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = tempfile.mkdtemp(prefix="inthon_test_")
        temp_path = Path(temp_dir)
        
        try:
            # í•„ìš”í•œ íŒŒì¼ë“¤ì„ ì„ì‹œ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
            # model.pyëŠ” ì´ë¯¸ ë¡œë“œë˜ì—ˆìœ¼ë¯€ë¡œ ë³µì‚¬ë§Œ í•˜ë©´ ë¨
            files_to_copy = [
                "model.py",
                "best_model.pt",
                "do_not_edit",
            ]
            
            # ì¶”ê°€ë¡œ í•„ìš”í•œ íŒŒì¼ë“¤ë„ ë³µì‚¬ (import ì˜¤ë¥˜ ë°©ì§€)
            optional_files = [
                "config.py",
                "dataloader.py",
            ]
            
            copied_files = []
            for file_name in files_to_copy:
                src = submission_path / file_name
                if src.exists():
                    if src.is_dir():
                        shutil.copytree(src, temp_path / file_name)
                    else:
                        shutil.copy2(src, temp_path / file_name)
                    copied_files.append(file_name)
            
            for file_name in optional_files:
                src = submission_path / file_name
                if src.exists():
                    shutil.copy2(src, temp_path / file_name)
            
            # best_model.ptê°€ ì—†ìœ¼ë©´ ê²½ê³ 
            if "best_model.pt" not in copied_files:
                print("   âš ï¸  best_model.ptê°€ ì—†ì–´ ìƒëŒ€ ê²½ë¡œ ê²€ì¦ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                print("   âš ï¸  (ëª¨ë¸ ì´ˆê¸°í™”ëŠ” ì„±ê³µí–ˆì§€ë§Œ, ë‹¤ë¥¸ ë””ë ‰í† ë¦¬ í…ŒìŠ¤íŠ¸ëŠ” ë¶ˆê°€ëŠ¥)")
            else:
                # ì„ì‹œ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì—¬ ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„
                original_cwd_for_test = os.getcwd()
                os.chdir(temp_path)
                
                try:
                    # ëª¨ë“ˆì„ ë‹¤ì‹œ ë¡œë“œ (ìƒˆ ë””ë ‰í† ë¦¬ì—ì„œ)
                    spec = importlib.util.spec_from_file_location("submission_test", temp_path / "model.py")
                    test_module = importlib.util.module_from_spec(spec)
                    assert spec is not None and spec.loader is not None
                    spec.loader.exec_module(test_module)
                    
                    # ìƒˆ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„
                    TestModelClass = getattr(test_module, "Model")
                    test_model = TestModelClass()
                    
                    # predict í…ŒìŠ¤íŠ¸
                    test_result = test_model.predict("12+34")
                    
                    if isinstance(test_result, str):
                        print("âœ… ìƒëŒ€ ê²½ë¡œ ì‚¬ìš© í™•ì¸ë¨ (ë‹¤ë¥¸ ë””ë ‰í† ë¦¬ì—ì„œë„ ì •ìƒ ì‘ë™)")
                    else:
                        print("âŒ ìƒëŒ€ ê²½ë¡œ ê²€ì¦ ì‹¤íŒ¨: predict() ë°˜í™˜ íƒ€ì… ì˜¤ë¥˜")
                        
                except FileNotFoundError as e:
                    print(f"âŒ ìƒëŒ€ ê²½ë¡œ ê²€ì¦ ì‹¤íŒ¨: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    print(f"   ì˜¤ë¥˜: {e}")
                    print("   âš ï¸  ì ˆëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤ (ê·œì¹™ ì œ9ì¡° â‘¢í•­)")
                except Exception as e:
                    print(f"âŒ ìƒëŒ€ ê²½ë¡œ ê²€ì¦ ì‹¤íŒ¨: ë‹¤ë¥¸ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
                    print(f"   ì˜¤ë¥˜: {e}")
                    print("   âš ï¸  ì ˆëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤ (ê·œì¹™ ì œ9ì¡° â‘¢í•­)")
                finally:
                    os.chdir(original_cwd_for_test)
                    
        finally:
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
            try:
                shutil.rmtree(temp_dir)
            except Exception:
                pass  # ì •ë¦¬ ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ
        
        # GPU ì‚¬ìš© ì—¬ë¶€ ì²´í¬ (ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰)
        print("\n[GPU ì‚¬ìš© ì—¬ë¶€ ê²€ì¦]")
        
        # ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ì™€ ë²„í¼ë¥¼ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ ì‹¤ì œ device í™•ì¸
        devices = get_all_devices_from_model(model)
        
        if not devices:
            print("âš ï¸  ëª¨ë¸ì—ì„œ íŒŒë¼ë¯¸í„°ë‚˜ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # CPUì™€ CUDA device ë¶„ë¦¬
            cuda_devices = {d for d in devices if d.startswith("cuda")}
            cpu_devices = {d for d in devices if d == "cpu"}
            
            if cuda_devices and cpu_devices:
                print("âš ï¸  ê²½ê³ : ëª¨ë¸ì˜ ì¼ë¶€ëŠ” GPUì—, ì¼ë¶€ëŠ” CPUì— ìˆìŠµë‹ˆë‹¤.")
                print(f"   GPU device: {', '.join(sorted(cuda_devices))}")
                print(f"   CPU device: {', '.join(sorted(cpu_devices))}")
                print("   âš ï¸  ëª¨ë“  íŒŒë¼ë¯¸í„°ê°€ ê°™ì€ deviceì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
            elif cuda_devices:
                # GPU ì‚¬ìš© ì¤‘
                gpu_device = sorted(cuda_devices)[0]
                if torch.cuda.is_available():
                    device_index = int(gpu_device.split(":")[1]) if ":" in gpu_device else 0
                    gpu_name = torch.cuda.get_device_name(device_index)
                    print(f"âœ… GPU ì‚¬ìš© ì¤‘: {gpu_device}")
                    print(f"   GPU ì´ë¦„: {gpu_name}")
                    if len(cuda_devices) > 1:
                        print(f"   âš ï¸  ì—¬ëŸ¬ GPU device ë°œê²¬: {', '.join(sorted(cuda_devices))}")
                else:
                    print(f"âš ï¸  ê²½ê³ : CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œë° GPU ë””ë°”ì´ìŠ¤ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                    print(f"   ë°œê²¬ëœ device: {', '.join(sorted(cuda_devices))}")
            elif cpu_devices:
                print("âš ï¸  CPU ì‚¬ìš© ì¤‘")
                print("   âš ï¸  GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            else:
                print(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” device: {devices}")
        
        # device ì†ì„±ë„ í™•ì¸ (ì°¸ê³ ìš©)
        if hasattr(model, "device"):
            device_attr = model.device
            if isinstance(device_attr, torch.device):
                print(f"   (ì°¸ê³ : model.device = {device_attr})")
        
        # predict í…ŒìŠ¤íŠ¸
        if not hasattr(model, "predict"):
            print("âŒ Modelì— predict ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        test_input = "12+34"
        print(f"\n[predict í…ŒìŠ¤íŠ¸] ì…ë ¥='{test_input}'")

        # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
        try:
            # ì›Œë°ì—… (ì²« ì‹¤í–‰ì€ ëŠë¦´ ìˆ˜ ìˆìŒ)
            _ = model.predict(test_input)
            
            # ì‹¤ì œ ì‹œê°„ ì¸¡ì •
            num_runs = 10  # ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•˜ì—¬ í‰ê·  ì¸¡ì •
            times = []
            for _ in range(num_runs):
                start_time = time.perf_counter()
                pred = model.predict(test_input)
                end_time = time.perf_counter()
                times.append(end_time - start_time)
            
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            
        except Exception as e:
            print(f"âŒ predict í˜¸ì¶œ ì¤‘ ì˜ˆì™¸: {e}")
            return

        if not isinstance(pred, str):
            print(f"âŒ predict()ëŠ” ë°˜ë“œì‹œ ë¬¸ìì—´ì„ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ íƒ€ì…: {type(pred)}")
            return
        
        print(f"âœ… predict() ì„±ê³µ, ë°˜í™˜ê°’: '{pred}' (type={type(pred)})")
        
        # ì‹¤í–‰ ì‹œê°„ ì •ë³´ ì¶œë ¥
        print(f"\n[ì‹¤í–‰ ì‹œê°„ ì¸¡ì •]")
        print(f"   í‰ê·  ì‹¤í–‰ ì‹œê°„: {avg_time*1000:.2f}ms ({avg_time:.4f}ì´ˆ)")
        print(f"   ìµœì†Œ ì‹¤í–‰ ì‹œê°„: {min_time*1000:.2f}ms ({min_time:.4f}ì´ˆ)")
        print(f"   ìµœëŒ€ ì‹¤í–‰ ì‹œê°„: {max_time*1000:.2f}ms ({max_time:.4f}ì´ˆ)")
        
        # ì „ì²´ í‰ê°€ ì‹œê°„ ì˜ˆì¸¡ (10000ê°œ ìƒ˜í”Œ ê¸°ì¤€)
        total_samples = 10000
        server_setup_time_seconds = 3 * 60  # ì„œë²„ ì„¸íŒ… ì‹œê°„ 3ë¶„
        inference_time_seconds = avg_time * total_samples
        estimated_total_seconds = server_setup_time_seconds + inference_time_seconds
        estimated_minutes = estimated_total_seconds / 60
        estimated_hours = estimated_minutes / 60
        
        print(f"\n[ì „ì²´ í‰ê°€ ì‹œê°„ ì˜ˆì¸¡] (10000ê°œ ìƒ˜í”Œ ê¸°ì¤€)")
        print(f"   ì„œë²„ ì„¸íŒ… ì‹œê°„: {server_setup_time_seconds/60:.0f}ë¶„")
        print(f"   ì¶”ë¡  ì‹œê°„: {inference_time_seconds:.1f}ì´ˆ ({inference_time_seconds/60:.2f}ë¶„)")
        print(f"   ì´ ì˜ˆìƒ ì‹œê°„: ", end="")
        if estimated_minutes < 1:
            print(f"{estimated_total_seconds:.1f}ì´ˆ")
        elif estimated_hours < 1:
            print(f"{estimated_minutes:.1f}ë¶„ ({estimated_total_seconds:.0f}ì´ˆ)")
        else:
            print(f"{estimated_hours:.2f}ì‹œê°„ ({estimated_minutes:.1f}ë¶„)")
        
        print("\nğŸ‰ local_test í†µê³¼! InThon ê·œì • í˜•ì‹ OK.")
    finally:
        os.chdir(original_cwd)

if __name__ == "__main__":

    if len(sys.argv) != 2:
        print("ì‚¬ìš©ë²•: python local_test.py <ì œì¶œ ë””ë ‰í† ë¦¬ ê²½ë¡œ>")
    else:

        run_local_test(sys.argv[1])

